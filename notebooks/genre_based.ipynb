{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e4601c",
   "metadata": {},
   "source": [
    "# Genre-Based Link Prediction\n",
    "\n",
    "This notebook performs link prediction with genre similarity on the Discogs collaboration data. This notebook uses shared musical genres instead of the structural features.\n",
    "\n",
    "Our hypothesis is that artists who share similar genres are more likely to collaborate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2116769",
   "metadata": {},
   "source": [
    "## Imports and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "\n",
    "artists = pd.read_parquet('../data/final_data_processed/discogs_artists.parquet')\n",
    "\n",
    "edges = pd.read_parquet('../data/final_data_processed/discogs_edges.parquet')\n",
    "\n",
    "artists_genres = pd.read_parquet('../data/final_data_processed/discogs_artists_and_genres.parquet')\n",
    "print(f\"\\nSample genres: {artists_genres.head(3)}\")\n",
    "print(f\"Artists with genres: {artists_genres.shape}\")\n",
    "\n",
    "print(f\"Artists: {artists.shape}\")\n",
    "print(f\"Edges: {edges.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508801c",
   "metadata": {},
   "source": [
    "## Sorting Data and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c97cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_sorted = edges.sort_values(by='release_year')\n",
    "edges_sorted[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d184a242",
   "metadata": {},
   "source": [
    "### Era-based Split\n",
    "\n",
    "Here is something we noticed, the data starts from 1897, if we do just one single split on the data, then it does not make any sense of whatever prediction we will get, because music has seen such a change in eras, and also artists are not even the same in these eras. \n",
    "\n",
    "What we are going to do to tackle this is we have our edges sorted chronologically, so we will divide our entire Discogs dataset into different musical eras. This way, we preserve the genre ecosystems, the change in artists, the technology and recording environments, and actually get predictions that are better explainable.\n",
    "\n",
    "It will also help us analyze and understand how collaboration changed over years, which will make our entire analysis even more insightful.\n",
    "\n",
    "This it the division we will follow:\n",
    "- Era 1: Early Recording (1897 - 1945)\n",
    "- Era 2: Post-WWII / Early Rock (1946 - 1965)\n",
    "- Era 3: Classic Rock / Studio Revolution (1966 - 1982)\n",
    "- Era 4: MTV and Digital Sampling (1983 - 1999)\n",
    "- Era 5: The Internet / Streaming Era (2000 - Present)\n",
    "\n",
    "For each era, we will:\n",
    "- Filter the edges inside the year range\n",
    "- Recompute the artists set (all unqiue IDs appearing in that era)\n",
    "- Store each era as its own DataFram for later train/test splitting\n",
    "\n",
    "This way, we can run independent link prediction models inside each era."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Now, based on earlier divisions, let us create our 5 data splits\n",
    "\n",
    "# Note: For each era, we will first extract the edges from edges_sorted for the relevant release years, following\n",
    "# which we will build the era's artists df using the unique() source_id and target_ids of those edges\n",
    "\n",
    "# Note: Era 1\n",
    "era1_edges = edges_sorted[(edges_sorted['release_year'] >= 1897) & (edges_sorted['release_year'] <= 1945)]\n",
    "\n",
    "era1_artists = pd.DataFrame({'discogs_artist_id': pd.unique(pd.concat([era1_edges.source_id, era1_edges.target_id]))})\n",
    "print('Era 1')\n",
    "print(len(era1_edges), len(era1_artists))\n",
    "\n",
    "# Note: Era 2\n",
    "era2_edges = edges_sorted[(edges_sorted['release_year'] >= 1946) & (edges_sorted['release_year'] <= 1965)]\n",
    "\n",
    "era2_artists = pd.DataFrame({'discogs_artist_id': pd.unique(pd.concat([era2_edges.source_id, era2_edges.target_id]))})\n",
    "print('Era 2')\n",
    "print(len(era2_edges), len(era2_artists))\n",
    "\n",
    "# Note: Era 3\n",
    "era3_edges = edges_sorted[(edges_sorted['release_year'] >= 1966) & (edges_sorted['release_year'] <= 1982)]\n",
    "\n",
    "era3_artists = pd.DataFrame({'discogs_artist_id': pd.unique(pd.concat([era3_edges.source_id, era3_edges.target_id]))})\n",
    "print('Era 3')\n",
    "print(len(era3_edges), len(era3_artists))\n",
    "\n",
    "# Note: Era 4\n",
    "era4_edges = edges_sorted[(edges_sorted['release_year'] >= 1983) & (edges_sorted['release_year'] <= 2000)]\n",
    "\n",
    "era4_artists = pd.DataFrame({'discogs_artist_id': pd.unique(pd.concat([era4_edges.source_id, era4_edges.target_id]))})\n",
    "print('Era 4')\n",
    "print(len(era4_edges), len(era4_artists))\n",
    "\n",
    "# Note: Era 5\n",
    "era5_edges = edges_sorted[(edges_sorted['release_year'] >= 2000) & (edges_sorted['release_year'] <= 2025)]\n",
    "\n",
    "era5_artists = pd.DataFrame({'discogs_artist_id': pd.unique(pd.concat([era5_edges.source_id, era5_edges.target_id]))})\n",
    "print('Era 5')\n",
    "print(len(era5_edges), len(era5_artists))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0244433",
   "metadata": {},
   "source": [
    "## Train/Test Split for Each Era\n",
    "\n",
    "In this bit, we will get the train/test splits for each musical era, and because we are doing a time based chronological split, we will follow a temporal link prediction methods (meaning we cannot use future collaborations to predict past ones), which will be as follows:\n",
    "\n",
    "1. We will sort all the edges by the release_year\n",
    "2. We will select a cutoff year for each era\n",
    "3. All collaborations before or equal to the cut off year go into the train graph, and the latter into the test graph\n",
    "4. Only the test edges where both nodes already exist in the train graph are kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We will be using a function to get the cutoff year\n",
    "def compute_cutoff(df, pct=0.8):\n",
    "    years = df['release_year'].sort_values().unique()\n",
    "    return years[int(len(years) * pct)]\n",
    "\n",
    "# Note: Now just run it on the diff era edges we have\n",
    "cut1 = compute_cutoff(era1_edges)\n",
    "cut2 = compute_cutoff(era2_edges)\n",
    "cut3 = compute_cutoff(era3_edges)\n",
    "cut4 = compute_cutoff(era4_edges)\n",
    "cut5 = compute_cutoff(era5_edges)\n",
    "\n",
    "cut1, cut2, cut3, cut4, cut5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Now that we have our 3 cuts, we will implement that to get our train, test data for all 5 eras:\n",
    "\n",
    "# Era 1 train/test split\n",
    "era1_train = era1_edges[era1_edges['release_year'] <= cut1]\n",
    "era1_test  = era1_edges[era1_edges['release_year'] > cut1]\n",
    "print(f'Era 1: {len(era1_train), len(era1_test)}')\n",
    "\n",
    "# Era 2 train/test split\n",
    "\n",
    "era2_train = era2_edges[era2_edges['release_year'] <= cut2]\n",
    "era2_test  = era2_edges[era2_edges['release_year'] > cut2]\n",
    "print(f'Era 2: {len(era2_train), len(era2_test)}')\n",
    "\n",
    "# Era 3 train/test split\n",
    "\n",
    "era3_train = era3_edges[era3_edges['release_year'] <= cut3]\n",
    "era3_test  = era3_edges[era3_edges['release_year'] > cut3]\n",
    "print(f'Era 3: {len(era3_train), len(era3_test)}')\n",
    "\n",
    "# Era 4 train/test split\n",
    "\n",
    "era4_train = era4_edges[era4_edges['release_year'] <= cut4]\n",
    "era4_test  = era4_edges[era4_edges['release_year'] > cut4]\n",
    "print(f'Era 4: {len(era4_train), len(era4_test)}')\n",
    "\n",
    "# Era 5 train/test split\n",
    "\n",
    "era5_train = era5_edges[era5_edges['release_year'] <= cut5]\n",
    "era5_test  = era5_edges[era5_edges['release_year'] > cut5]\n",
    "print(f'Era 5: {len(era5_train), len(era5_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039087e3",
   "metadata": {},
   "source": [
    "### Ensure Valid Test Edges\n",
    "\n",
    "There is one thing though, a test edge (u,v) is only meaningful if both the nodes are in the train graph, otherwise the model will not be able to predict it using structural information, aka just looking at the graph data, of the train data. Therefore, we will filter the test sets to only include edges wehre: source_id is in train_nodes, target_id is in test_nodes.\n",
    "\n",
    "A more explanable way to put this is, if we think about a cut off year, then the model only knows the artists up until that point, then if new artists come into play after that year then the model could not possible predict the artist's future collaborations because they never existed in the graph until after the test period began. Same idea for artists whose careers end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57339e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We will use a function to help us filter as we discribed earlier\n",
    "def filter_artist_only_after_test(train_edges, test_edges):\n",
    "    train_nodes = set(train_edges['source_id']).union(train_edges['target_id'])\n",
    "    return test_edges[(test_edges['source_id'].isin(train_nodes)) & (test_edges['target_id'].isin(train_nodes))] \n",
    "\n",
    "# Note: Now we just apply this filtering to each era\n",
    "era1_test = filter_artist_only_after_test(era1_train, era1_test)\n",
    "era2_test = filter_artist_only_after_test(era2_train, era2_test)\n",
    "era3_test = filter_artist_only_after_test(era3_train, era3_test)\n",
    "era4_test = filter_artist_only_after_test(era4_train, era4_test)\n",
    "era5_test = filter_artist_only_after_test(era5_train, era5_test)\n",
    "\n",
    "# Note: Now let us just print the final lengths after all processing before moving on to making the actual graphs\n",
    "print(\"Era 1:\", len(era1_train), len(era1_test))\n",
    "print(\"Era 2:\", len(era2_train), len(era2_test))\n",
    "print(\"Era 3:\", len(era3_train), len(era3_test))\n",
    "print(\"Era 4:\", len(era4_train), len(era4_test))\n",
    "print(\"Era 5:\", len(era5_train), len(era5_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff83ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Define eras dictionary for easy iteration\n",
    "eras = {\n",
    "    \"Era1\": (era1_train, era1_test),\n",
    "    \"Era2\": (era2_train, era2_test),\n",
    "    \"Era3\": (era3_train, era3_test),\n",
    "    \"Era4\": (era4_train, era4_test),\n",
    "    \"Era5\": (era5_train, era5_test)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8093128f",
   "metadata": {},
   "source": [
    "## Build Train Graph\n",
    "\n",
    "From here on out, until we do the final prediction on each train dataset for each era, what we will do is we will create functions such that we can then run these functions on each era to get the predictions.\n",
    "\n",
    "For the first one, we are going to be building a train graph, given teh train edges for an era, we will construct an undirected nx Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9291cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_graph(train_df):\n",
    "    # Note: We will be building the training graph given the training edges of an era\n",
    "    G = nx.Graph()\n",
    "    for _, row in train_df.iterrows():\n",
    "        G.add_edge(row['source_id'], row['target_id'])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66f33b",
   "metadata": {},
   "source": [
    "## Sampling Negative Edges\n",
    "\n",
    "In this helper function, we will sample negative edges (u,v) such that: u != v, u and v both exist in the train graph and there is no edge u,v in the train graph\n",
    "\n",
    "Basically, this aligns with the link prediction with the original Liben-Nowell % Kleinberg (2007) work, where the authors implicitly treat all non-edges as negative samples when ranking node similarity. Because our graph is very large, we follow the standard scalable apporximation used in modern graph mining and randomly sample an equal-szied set of non-edges to serve as negatives.\n",
    "\n",
    "Reference: David Liben-Nowell and Jon Kleinberg. 2003. The link prediction problem for social networks. In Proceedings of the twelfth international conference on Information and knowledge management (CIKM '03). Association for Computing Machinery, New York, NY, USA, 556â€“559. https://doi.org/10.1145/956863.956972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_negative_edges(G, positive_edges, seed = 42):\n",
    "    # Note: Here we will sample the engative edges equal in number to the positive edges\n",
    "    random.seed(seed)\n",
    "    nodes = list(G.nodes())\n",
    "    negatives = set()\n",
    "    target_count = len(positive_edges)\n",
    "\n",
    "    while len(negatives) < target_count:\n",
    "        u, v = random.sample(nodes, 2)\n",
    "        if not G.has_edge(u, v):\n",
    "            negatives.add(tuple(sorted((u, v))))\n",
    "    return list(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce90111",
   "metadata": {},
   "source": [
    "## Genre Preprocessing\n",
    "\n",
    "Before computing genre-based features, we need to:\n",
    "1. Put all artists that are the same genre in the same set\n",
    "2. Handle \"Unknown\" genres by treating them as an empty set (this way, they will basically have zero similarity with the others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f13ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {}\n",
    "for _, row in artists_genres.iterrows():\n",
    "    artist_id = row['discogs_artist_id']\n",
    "    genres = row['genres']\n",
    "    \n",
    "    # filtering the unknown\n",
    "    real_genres = [g for g in genres if g != \"Unknown\"]\n",
    "    genre_dict[artist_id] = set(real_genres)\n",
    "\n",
    "print(f\"total artists: {len(genre_dict)}\")\n",
    "print(f\"artists with no unknowns: {sum(1 for g in genre_dict.values() if len(g) > 0)}\")\n",
    "print(f\"artists wtih unknowns: {sum(1 for g in genre_dict.values() if len(g) == 0)}\")\n",
    "\n",
    "# Sample\n",
    "sample_artists = list(genre_dict.items())[:5]\n",
    "for artist_id, genres in sample_artists:\n",
    "    print(f\"  Artist {artist_id}: {genres}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2f2a1",
   "metadata": {},
   "source": [
    "## Genre Similarity Functions\n",
    "\n",
    "Now compute our three genre-based features:\n",
    "1. **Genre Jaccard**\n",
    "2. **Genre Overlap**\n",
    "3. **Same Genre Flag**\n",
    "\n",
    "These capture different aspects of genre homophily - the tendency for artists with similar musical styles to collaborate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_genre_features(edge_list, genre_dict):\n",
    "    jaccard_scores = []\n",
    "    overlap_scores = []\n",
    "    same_genre_flags = []\n",
    "    \n",
    "    for u, v in edge_list:\n",
    "        genres_u = genre_dict.get(u, set())\n",
    "        genres_v = genre_dict.get(v, set())\n",
    "        \n",
    "        intersection = genres_u & genres_v\n",
    "        union = genres_u | genres_v\n",
    "        \n",
    "        # this is unecessary for this set but keep it here in case we run this on a set that has artists with no genre.\n",
    "        if len(union) > 0:\n",
    "            jaccard = len(intersection) / len(union)\n",
    "        else:\n",
    "            jaccard = 0.0\n",
    "        \n",
    "        # for same genre calculation.\n",
    "        overlap = len(intersection)\n",
    "        \n",
    "        # same genre\n",
    "        same_genre = 1 if overlap > 0 else 0\n",
    "        \n",
    "        jaccard_scores.append(jaccard)\n",
    "        overlap_scores.append(overlap)\n",
    "        same_genre_flags.append(same_genre)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'u': [u for u, v in edge_list],\n",
    "        'v': [v for u, v in edge_list],\n",
    "        'genre_jaccard': jaccard_scores,\n",
    "        'genre_overlap': overlap_scores,\n",
    "        'same_genre': same_genre_flags\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57227dc5",
   "metadata": {},
   "source": [
    "## Genre Based Link Prediction Pipeline\n",
    "\n",
    "This pipeline follows the same structure as the structural features but uses genre similarity instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_genre_pipeline_for_era(train_df, test_df, genre_dict):\n",
    "    G = build_train_graph(train_df)\n",
    "    \n",
    "    positives = list(zip(test_df['source_id'], test_df['target_id']))\n",
    "    \n",
    "    negatives = sample_negative_edges(G, positives)\n",
    "    \n",
    "    all_edges = positives + negatives\n",
    "    labels = [1] * len(positives) + [0] * len(negatives)\n",
    "    \n",
    "    scores_df = compute_genre_features(all_edges, genre_dict)\n",
    "    scores_df['label'] = labels\n",
    "    \n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2241a2",
   "metadata": {},
   "source": [
    "## Run Genre-Based Pipeline on All Eras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177421ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genre_results = {}\n",
    "\n",
    "for era, (train_df, test_df) in eras.items():\n",
    "    print(f'Running genre-based pipeline for {era}...')\n",
    "    result_df = run_genre_pipeline_for_era(train_df, test_df, genre_dict)\n",
    "    all_genre_results[era] = result_df\n",
    "    print(f'  {era}: {len(result_df)} edge pairs ({result_df[\"label\"].sum()} positive, {(1-result_df[\"label\"]).sum()} negative)')\n",
    "    print(f'  Genre overlap > 0: {(result_df[\"genre_overlap\"] > 0).sum()} pairs')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a6247",
   "metadata": {},
   "source": [
    "## Evaluate Genre-Based Features\n",
    "\n",
    "Compute the AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be24c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genre_aucs = {}\n",
    "\n",
    "for era, genre_df in all_genre_results.items():\n",
    "    print(f\"\\n{era} Genre-Based AUC:\")\n",
    "    genre_aucs = {}\n",
    "    \n",
    "    for feature in ['genre_jaccard', 'genre_overlap', 'same_genre']:\n",
    "        # Check if feature has variation\n",
    "        if genre_df[feature].nunique() > 1:\n",
    "            auc = roc_auc_score(genre_df['label'], genre_df[feature])\n",
    "            genre_aucs[feature] = auc\n",
    "            print(f\"  {feature.upper()}: {auc:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {feature.upper()}: N/A (constant)\")\n",
    "            genre_aucs[feature] = None\n",
    "    \n",
    "    all_genre_aucs[era] = genre_aucs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af17a1",
   "metadata": {},
   "source": [
    "## Visualize Genre Homophily\n",
    "\n",
    "Let's make some graphs so we can see if the artists who share genres actually collaborate more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a919581",
   "metadata": {},
   "outputs": [],
   "source": [
    "homophily_data = []\n",
    "\n",
    "for era, genre_df in all_genre_results.items():\n",
    "    pos_df = genre_df[genre_df['label'] == 1]\n",
    "    neg_df = genre_df[genre_df['label'] == 0]\n",
    "    \n",
    "    pos_rate = (pos_df['same_genre'] == 1).mean()\n",
    "    neg_rate = (neg_df['same_genre'] == 1).mean()\n",
    "    difference = pos_rate - neg_rate\n",
    "    \n",
    "    homophily_data.append({\n",
    "        'era': era,\n",
    "        'Collaborations': pos_rate,\n",
    "        'Non-Collaborations': neg_rate,\n",
    "        'Difference': difference\n",
    "    })\n",
    "\n",
    "homophily_df = pd.DataFrame(homophily_data)\n",
    "print(homophily_df)\n",
    "\n",
    "# Plot 1: same-genre\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(homophily_df))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, homophily_df['Collaborations'], width, label='Collaborations', alpha=0.8)\n",
    "plt.bar(x + width/2, homophily_df['Non-Collaborations'], width, label='Non-Collaborations', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Era', fontsize=12)\n",
    "plt.ylabel('Proportion with Shared Genre', fontsize=12)\n",
    "plt.title('Genre Homophily: Shared Genre Rates by Era', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x, homophily_df['era'])\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: diff between pos and neg\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(homophily_df['era'], homophily_df['Difference'], color='steelblue', alpha=0.8)\n",
    "plt.xlabel('Era', fontsize=12)\n",
    "plt.ylabel('Difference (Positive - Negative)', fontsize=12)\n",
    "plt.title('Genre Homophily Effect Across Eras', fontsize=14, fontweight='bold')\n",
    "plt.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd5fb4",
   "metadata": {},
   "source": [
    "## Detailed Metric Evaluation\n",
    "\n",
    "Beyond AUC, we'll compute comprehensive evaluation metrics for each genre-based feature:\n",
    "- **AUC**\n",
    "- **Precision**\n",
    "- **Recall**\n",
    "- **Hits@K**\n",
    "- **Score Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeCol(df, col):\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    if max_val - min_val > 0:\n",
    "        return (df[col] - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        return df[col]\n",
    "\n",
    "def evaluate(df, graphMetric, threshold=0.5):\n",
    "    df = df.copy()\n",
    "    df['score_normalized'] = normalizeCol(df, graphMetric)\n",
    "    \n",
    "    if df['score_normalized'].nunique() <= 1:\n",
    "        print(f\"\\n{graphMetric.upper()}: skipping\")\n",
    "        return None\n",
    "    \n",
    "    # AUC\n",
    "    auc = roc_auc_score(df['label'], df['score_normalized'])\n",
    "    \n",
    "    # Precision and Recall \n",
    "    df['pred'] = (df['score_normalized'] >= threshold).astype(int)\n",
    "    precision = precision_score(df['label'], df['pred'], zero_division=0)\n",
    "    recall = recall_score(df['label'], df['pred'], zero_division=0)\n",
    "    \n",
    "    # Hits@K (top 1000 predictions)\n",
    "    K = min(1000, len(df))\n",
    "    top_k_indices = df.nlargest(K, 'score_normalized').index\n",
    "    hits_at_k = df.loc[top_k_indices, 'label'].sum()\n",
    "    \n",
    "    print(f\"\\n{graphMetric.upper()} Evaluation:\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Precision@{threshold}: {precision:.4f}\")\n",
    "    print(f\"Recall@{threshold}: {recall:.4f}\")\n",
    "    print(f\"Hits@{K}: {hits_at_k}\")\n",
    "    \n",
    "    # Plot score distributions\n",
    "    pos_scores = df[df['label'] == 1]['score_normalized']\n",
    "    neg_scores = df[df['label'] == 0]['score_normalized']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(pos_scores, bins=30, alpha=0.6, label='Collaborations', color='green', edgecolor='black')\n",
    "    plt.hist(neg_scores, bins=30, alpha=0.6, label='Non-Collaborations', color='red', edgecolor='black')\n",
    "    plt.axvline(x=threshold, color='blue', linestyle='--', linewidth=2, label=f'Threshold={threshold}')\n",
    "    plt.xlabel('Normalized Score', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.title(f'{graphMetric.upper()} Score Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'hits_at_k': hits_at_k\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d96449",
   "metadata": {},
   "source": [
    "## Evaluate Genre Features Across All Eras\n",
    "\n",
    "Run comprehensive evaluation for all genre-based features across all 5 musical eras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_eval_results = []\n",
    "\n",
    "for era, genre_df in all_genre_results.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {era}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    for metric in ['genre_jaccard', 'genre_overlap', 'same_genre']:\n",
    "        result = evaluate(genre_df, metric, threshold=0.5)\n",
    "        if result:\n",
    "            genre_eval_results.append({\n",
    "                'era': era,\n",
    "                'metric': metric,\n",
    "                **result\n",
    "            })\n",
    "            \n",
    "#print out a summary\n",
    "genre_eval_df = pd.DataFrame(genre_eval_results)\n",
    "print(\"\\n\\nSummary of Genre Feature Evaluation:\")\n",
    "print(genre_eval_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786eac2",
   "metadata": {},
   "source": [
    "## Combined Evaluation Visualization\n",
    "\n",
    "Create separate plots comparing all genre features across eras for each metric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. AUC Comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_auc = genre_eval_df.pivot(index='era', columns='metric', values='auc')\n",
    "pivot_auc.plot(kind='bar', width=0.8)\n",
    "plt.title('Genre Features: AUC Comparison Across Eras', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Era', fontsize=12)\n",
    "plt.ylabel('AUC Score', fontsize=12)\n",
    "plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Precision Comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_precision = genre_eval_df.pivot(index='era', columns='metric', values='precision')\n",
    "pivot_precision.plot(kind='bar', width=0.8)\n",
    "plt.title('Genre Features: Precision Comparison Across Eras', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Era', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Recall Comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_recall = genre_eval_df.pivot(index='era', columns='metric', values='recall')\n",
    "pivot_recall.plot(kind='bar', width=0.8)\n",
    "plt.title('Genre Features: Recall Comparison Across Eras', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Era', fontsize=12)\n",
    "plt.ylabel('Recall', fontsize=12)\n",
    "plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Hits@K Comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_hits = genre_eval_df.pivot(index='era', columns='metric', values='hits_at_k')\n",
    "pivot_hits.plot(kind='bar', width=0.8)\n",
    "plt.title('Genre Features: Hits@K Comparison Across Eras', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Era', fontsize=12)\n",
    "plt.ylabel('Hits@K', fontsize=12)\n",
    "plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
