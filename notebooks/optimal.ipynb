{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714f409d",
   "metadata": {},
   "source": [
    "# Combining Learnings\n",
    "\n",
    "Through testing with strucutral-based link prediction and community-based link prediction, we've seen that an optimal combination of both of these techniques should yield a more optimal model. Here, we will implement this:\n",
    "\n",
    "For this model testing we will only work with 1000 artists from era 5 with successful API calls. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b681f6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5673764, 3), (1045947, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Imports\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "artists = pd.read_parquet('../data/final_data_processed/discogs_artists.parquet')\n",
    "edges = pd.read_parquet('../data/final_data_processed/discogs_edges.parquet') # Note: These will be our nodes\n",
    "\n",
    "edges.shape, artists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfbb3f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Era 5\n",
      "2338167 620672\n",
      "  discogs_artist_id\n",
      "0            115466\n",
      "1            833554\n",
      "2              1768\n",
      "3             65718\n",
      "4            882018\n"
     ]
    }
   ],
   "source": [
    "# Note: First we will sort the edges chronologically\n",
    "edges_sorted = edges.sort_values(by='release_year')\n",
    "edges_sorted[:100]\n",
    "\n",
    "era5_edges = edges_sorted[(edges_sorted['release_year'] >= 2000) & (edges_sorted['release_year'] <= 2025)]\n",
    "\n",
    "era5_artists = pd.DataFrame({'discogs_artist_id': pd.unique(pd.concat([era5_edges.source_id, era5_edges.target_id]))})\n",
    "print('Era 5')\n",
    "print(len(era5_edges), len(era5_artists))\n",
    "print(era5_artists.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7968972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id                    name         realname  \\\n",
      "0               1           The Persuader  Jesper Dahlbäck   \n",
      "1               2  Mr. James Barth & A.D.              NaN   \n",
      "2               3               Josh Wink   Josh Winkelman   \n",
      "3               4           Johannes Heil    Johannes Heil   \n",
      "4               5              Heiko Laux       Heiko Laux   \n",
      "...           ...                     ...              ...   \n",
      "9798342  16856335             Izumi Kohki              NaN   \n",
      "9798343  16856338                  Kate08        Kate Webb   \n",
      "9798344  16856341   The Evil B-Side Twins              NaN   \n",
      "9798345  16856347             Carol Lundy              NaN   \n",
      "9798346  16856350            문선 (Moonsun)              NaN   \n",
      "\n",
      "                                                   profile  \\\n",
      "0        Electronic artist working out of Stockholm, ac...   \n",
      "1                                                      NaN   \n",
      "2        Electronic music DJ, label owner, producer, an...   \n",
      "3        Electronic music producer, musician and live p...   \n",
      "4        German DJ and producer based in Berlin. He is ...   \n",
      "...                                                    ...   \n",
      "9798342                                                NaN   \n",
      "9798343                                                NaN   \n",
      "9798344                                                NaN   \n",
      "9798345                                                NaN   \n",
      "9798346                                                NaN   \n",
      "\n",
      "                data_quality  urls  namevariations  aliases  members  groups  \n",
      "0                 Needs Vote   NaN             NaN      NaN      NaN     NaN  \n",
      "1                    Correct   NaN             NaN      NaN      NaN     NaN  \n",
      "2                 Needs Vote   NaN             NaN      NaN      NaN     NaN  \n",
      "3                 Needs Vote   NaN             NaN      NaN      NaN     NaN  \n",
      "4                 Needs Vote   NaN             NaN      NaN      NaN     NaN  \n",
      "...                      ...   ...             ...      ...      ...     ...  \n",
      "9798342  Needs Major Changes   NaN             NaN      NaN      NaN     NaN  \n",
      "9798343           Needs Vote   NaN             NaN      NaN      NaN     NaN  \n",
      "9798344  Needs Major Changes   NaN             NaN      NaN      NaN     NaN  \n",
      "9798345  Needs Major Changes   NaN             NaN      NaN      NaN     NaN  \n",
      "9798346           Needs Vote   NaN             NaN      NaN      NaN     NaN  \n",
      "\n",
      "[9798347 rows x 10 columns]\n",
      "Justin Bieber\n",
      "Successfully retrieved genres for 1000 artists.\n",
      "[('115466', {'name': 'Nikolai Rimsky-Korsakov', 'genres': ['classical']}), ('833554', {'name': 'Christa Ludwig', 'genres': ['opera', 'requiem', 'classical']}), ('1768', {'name': 'Bedrock', 'genres': ['trance', 'progressive house']}), ('882018', {'name': 'Jon Vickers', 'genres': ['opera']}), ('967916', {'name': 'Halfdan Kjerulf', 'genres': []})]\n"
     ]
    }
   ],
   "source": [
    "# sample for 1000 nodes that have API Call Hits \n",
    "\n",
    "# ========== Get Artist Names ==========\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "df_artistsID = pd.read_parquet(\"../data/final_data_processed/discogs_artists.parquet\")\n",
    "\n",
    "# print(df.head())\n",
    "\n",
    "# read the artists xml file so we can use the artist IDs from the parquet file to get artist names\n",
    "rows = []\n",
    "for event, elem in ET.iterparse(\"../data_raw/discogs_20251101_artists.xml\", events=(\"end\",)):\n",
    "    if elem.tag == \"artist\":   # repeating entry tag for Discogs artists\n",
    "        row = {child.tag: child.text for child in elem}\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "        # free memory\n",
    "        elem.clear()\n",
    "        parent = elem.getparent() if hasattr(elem, \"getparent\") else None\n",
    "        if parent is not None:\n",
    "            while parent.getprevious() is not None:\n",
    "                del parent[0]\n",
    "\n",
    "df_artistsNames = pd.DataFrame(rows)\n",
    "print(df_artistsNames.head(-5))\n",
    "\n",
    "\n",
    "\n",
    "# ========== SPOTIFY API FUNCTIONS ==========\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "load_dotenv()  # loads .env into environment\n",
    "\n",
    "client_id = os.getenv(\"SPOTIPY_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"SPOTIPY_CLIENT_SECRET\")\n",
    "\n",
    "auth_manager = SpotifyClientCredentials(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret\n",
    ")\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "\n",
    "# testing to see if the API call works\n",
    "artist = sp.artist(\"1uNFoZAHBGtllmzznpCI3s\")  # Justin Bieber ID\n",
    "print(artist[\"name\"])\n",
    "# method \n",
    "def get_artist(artist, market):\n",
    "    results = sp.search(q=f\"artist:{artist}\", type=\"artist\", limit=1, market=market)\n",
    "    items = results.get(\"artists\", {}).get(\"items\", [])\n",
    "\n",
    "    \n",
    "    return items[0] if items else None\n",
    "\n",
    "\n",
    "def get_artist_data(artist_name, market):\n",
    "    artist = get_artist(artist_name, market)\n",
    "    if artist:\n",
    "        return artist.get(\"genres\", [])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# ========== GET 1000 ARTISTS WITH SUCCESSFUL SPOTIFY API CALLS ==========\n",
    "artist_genres = {}\n",
    "\n",
    "for index, row in era5_artists.iterrows():\n",
    "    artist_id = row['discogs_artist_id']\n",
    "    artist_name_row = df_artistsNames[df_artistsNames['id'] == str(artist_id)]\n",
    "    if not artist_name_row.empty:\n",
    "        artist_name = artist_name_row.iloc[0]['name']\n",
    "        genres = get_artist_data(artist_name, market=\"US\")\n",
    "        if genres is not None:\n",
    "            artist_genres[artist_id] = {\n",
    "                'name': artist_name,\n",
    "                'genres': genres\n",
    "            }\n",
    "    if len(artist_genres) >= 1000:\n",
    "        break\n",
    "\n",
    "print(f\"Successfully retrieved genres for {len(artist_genres)} artists.\")\n",
    "print(list(artist_genres.items())[:5])  # Print first 5 entries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35ce9850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered edges count: 45596\n",
      "        source_id target_id  release_year\n",
      "723768     115466   1165499          2000\n",
      "3519660    833554    454293          2000\n",
      "3519661    882018    859036          2000\n",
      "4283352    967916   1674540          2000\n",
      "1304982    396036   2816584          2000\n",
      "Graph has 1000 nodes and 4208 edges.\n"
     ]
    }
   ],
   "source": [
    "# Get all edges where both source and target artists are in artist_genres\n",
    "filtered_edges = era5_edges[\n",
    "    era5_edges['source_id'].isin(artist_genres.keys()) &\n",
    "    era5_edges['target_id'].isin(artist_genres.keys())\n",
    "]\n",
    "\n",
    "print(f\"Filtered edges count: {len(filtered_edges)}\")\n",
    "print(filtered_edges.head())\n",
    "\n",
    "# Create the graph with the filtered edges and nodes\n",
    "# add nodes\n",
    "G = nx.Graph()\n",
    "\n",
    "for artist_id in artist_genres.keys():\n",
    "    G.add_node(artist_id, name=artist_genres[artist_id]['name'], genres=artist_genres[artist_id]['genres']) \n",
    "\n",
    "# add edges\n",
    "for _, row in filtered_edges.iterrows():\n",
    "    G.add_edge(row['source_id'], row['target_id'], release_year=row['release_year'])\n",
    "\n",
    "print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220aff60",
   "metadata": {},
   "source": [
    "### Prediction Design\n",
    "\n",
    "We want to create a hyprid, weighted model:     Score(u, v) = w1 * CN + w2 * JC + w3 * GO + w4 * LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39c21b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  source_id target_id  common_neighbors  jaccard_coefficient  genre_overlap  \\\n",
      "0    115466    833554          0.157025             0.226190       0.333333   \n",
      "1    115466      1768          0.000000             0.000000       0.000000   \n",
      "2    115466    882018          0.107438             0.166667       0.000000   \n",
      "3    115466    967916          0.008264             0.015152       0.000000   \n",
      "4    115466    265660          0.008264             0.015152       0.000000   \n",
      "\n",
      "   community_overlap  edge_exists  \n",
      "0                  0            0  \n",
      "1                  0            0  \n",
      "2                  0            0  \n",
      "3                  0            0  \n",
      "4                  0            0  \n"
     ]
    }
   ],
   "source": [
    "# # ========== CALCULATE CN FOR TEST EDGES ==========\n",
    "# # Create graph from train edges\n",
    "# # --- IGNORE ---\n",
    "# # Calculate Common Neighbors for each edge in the test set\n",
    "# cn_scores = []\n",
    "# for _, row in test_edges.iterrows():\n",
    "#     u = row['source_id']\n",
    "#     v = row['target_id']\n",
    "\n",
    "#     if u not in G or v not in G:\n",
    "#         cn_scores.append(0)     # or np.nan\n",
    "#         continue\n",
    "\n",
    "#     cn = len(list(nx.common_neighbors(G, u, v)))\n",
    "#     cn_scores.append(cn)\n",
    "\n",
    "# test_edges['common_neighbors'] = cn_scores\n",
    "# # print(test_edges[['source_id', 'target_id', 'common_neighbors']].head())\n",
    "\n",
    "# # ========== CALCULATE JACARD FOR TEST EDGES ==========\n",
    "# # Calculate Jaccard Coefficient for each edge in the test set\n",
    "# jaccard_scores = []\n",
    "# for _, row in test_edges.iterrows():\n",
    "#     u = row['source_id']\n",
    "#     v = row['target_id']\n",
    "\n",
    "#     if u not in G or v not in G:\n",
    "#         jaccard_scores.append(0)     # or np.nan\n",
    "#         continue\n",
    "\n",
    "#     preds = nx.jaccard_coefficient(G, [(u, v)])\n",
    "#     for _, _, p in preds:\n",
    "#         jaccard_scores.append(p)\n",
    "# test_edges['jaccard_coefficient'] = jaccard_scores\n",
    "# # print(test_edges[['source_id', 'target_id', 'jaccard_coefficient']].head())\n",
    "\n",
    "# # ========== CALCULATE GENRE OVERLAP FOR TEST EDGES ==========\n",
    "# # Calculate Genre Overlap for each edge in the test set\n",
    "# genre_overlap_scores = []\n",
    "# for _, row in test_edges.iterrows():\n",
    "#     u = row['source_id']\n",
    "#     v = row['target_id']\n",
    "\n",
    "#     genres_u = set(artist_genres[u]['genres'])\n",
    "#     genres_v = set(artist_genres[v]['genres'])\n",
    "\n",
    "#     if not genres_u or not genres_v:\n",
    "#         genre_overlap_scores.append(0)\n",
    "#         continue\n",
    "\n",
    "#     intersection = genres_u.intersection(genres_v)\n",
    "#     union = genres_u.union(genres_v)\n",
    "\n",
    "#     overlap_score = len(intersection) / len(union)\n",
    "#     genre_overlap_scores.append(overlap_score)\n",
    "\n",
    "# test_edges['genre_overlap'] = genre_overlap_scores\n",
    "# # print(test_edges[['source_id', 'target_id', 'genre_overlap']].head())\n",
    "\n",
    "# # ========== CALCULATE COMMUNITY OVERLAP FOR TEST EDGES ==========\n",
    "# # First, detect communities in the training graph using the Louvain method\n",
    "# # !pip install python-louvain\n",
    "# import community.community_louvain as community_louvain\n",
    "# partition = community_louvain.best_partition(G)   \n",
    "# # Calculate Community Overlap for each edge in the test set\n",
    "# community_overlap_scores = []\n",
    "# for _, row in test_edges.iterrows():    \n",
    "#     u = row['source_id']\n",
    "#     v = row['target_id']\n",
    "\n",
    "#     community_u = partition.get(u, -1)\n",
    "#     community_v = partition.get(v, -1)\n",
    "\n",
    "#     if community_u == -1 or community_v == -1:\n",
    "#         community_overlap_scores.append(0)\n",
    "#         continue\n",
    "\n",
    "#     overlap_score = 1 if community_u == community_v else 0\n",
    "#     community_overlap_scores.append(overlap_score)\n",
    "# test_edges['community_overlap'] = community_overlap_scores\n",
    "# # print(test_edges[['source_id', 'target_id', 'community_overlap']].head())\n",
    "\n",
    "# # ========== PRINT FINAL TEST EDGES WITH ALL SCORES ==========\n",
    "# # print in table format\n",
    "# print(test_edges[['source_id', 'target_id', 'common_neighbors', 'jaccard_coefficient', 'genre_overlap', 'community_overlap']].head(10))\n",
    "\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# --- 1. Get all node pairs ---\n",
    "all_nodes = list(G.nodes())\n",
    "all_pairs = list(itertools.combinations(all_nodes, 2))  # undirected, no self-loops\n",
    "\n",
    "# --- 2. Precompute clustering/community info if needed ---\n",
    "partition = community_louvain.best_partition(G)\n",
    "clustering = nx.clustering(G)  # optional if you want local clustering later\n",
    "\n",
    "rows = []\n",
    "for u, v in all_pairs:\n",
    "    # Common Neighbors\n",
    "    cn = len(list(nx.common_neighbors(G, u, v)))\n",
    "\n",
    "    # Jaccard\n",
    "    jaccard = list(nx.jaccard_coefficient(G, [(u, v)]))[0][2]\n",
    "\n",
    "    # Genre Overlap\n",
    "    genres_u = set(artist_genres.get(u, {}).get('genres', []))\n",
    "    genres_v = set(artist_genres.get(v, {}).get('genres', []))\n",
    "    if genres_u and genres_v:\n",
    "        go = len(genres_u & genres_v) / len(genres_u | genres_v)\n",
    "    else:\n",
    "        go = 0\n",
    "\n",
    "    # Community Overlap\n",
    "    cu = partition.get(u, -1)\n",
    "    cv = partition.get(v, -1)\n",
    "    co = 1 if cu != -1 and cu == cv else 0\n",
    "\n",
    "    # Edge label (1 if edge exists, 0 otherwise)\n",
    "    label = 1 if G.has_edge(u, v) else 0\n",
    "\n",
    "    rows.append((u, v, cn, jaccard, go, co, label))\n",
    "\n",
    "# --- 3. Make DataFrame ---\n",
    "link_pred_df = pd.DataFrame(rows, columns=[\n",
    "    'source_id', 'target_id', 'common_neighbors', \n",
    "    'jaccard_coefficient', 'genre_overlap', 'community_overlap', 'edge_exists'\n",
    "])\n",
    "\n",
    "\n",
    "#normalize common neighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "link_pred_df['common_neighbors'] = scaler.fit_transform(link_pred_df[['common_neighbors']])\n",
    "\n",
    "print(link_pred_df.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4febb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9933253253253254\n",
      "Best Parameters: CN_WEIGHT=0.6, JACCARD_WEIGHT=0.0, GENRE_WEIGHT=0.0, COMMUNITY_WEIGHT=0.4\n"
     ]
    }
   ],
   "source": [
    "# ========== BACKTESTING THE FULL LINK PREDICTION MODEL ==========\n",
    "def predict(common_neighbors, jaccard_coefficient, genre_overlap, community_overlap, CN_WEIGHT, JACCARD_WEIGHT, GENRE_WEIGHT, COMMUNITY_WEIGHT):\n",
    "    # Simple weighted sum model\n",
    "    score = (CN_WEIGHT * common_neighbors +\n",
    "             JACCARD_WEIGHT * jaccard_coefficient +\n",
    "             GENRE_WEIGHT * genre_overlap +\n",
    "             COMMUNITY_WEIGHT * community_overlap)\n",
    "    \n",
    "    return score\n",
    "\n",
    "# backtest each parameter betweei n 0 and 1 with step size 0.2\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for CN_WEIGHT in [0, 0.2, 0.4, 0.6, 0.8, 1]:\n",
    "    for JACCARD_WEIGHT in [0, 0.2, 0.4, 0.6, 0.8, 1]:\n",
    "        for GENRE_WEIGHT in [0, 0.2, 0.4, 0.6, 0.8, 1]:\n",
    "            for COMMUNITY_WEIGHT in [0, 0.2, 0.4, 0.6, 0.8, 1]:\n",
    "                # Normalize weights\n",
    "                total_weight = CN_WEIGHT + JACCARD_WEIGHT + GENRE_WEIGHT + COMMUNITY_WEIGHT\n",
    "                if total_weight == 0:\n",
    "                    continue\n",
    "                CN_W = CN_WEIGHT / total_weight\n",
    "                JACCARD_W = JACCARD_WEIGHT / total_weight\n",
    "                GENRE_W = GENRE_WEIGHT / total_weight\n",
    "                COMMUNITY_W = COMMUNITY_WEIGHT / total_weight\n",
    "                \n",
    "                # Make predictions\n",
    "                link_pred_df['predicted_score'] = link_pred_df.apply(\n",
    "                    lambda row: predict(\n",
    "                        row['common_neighbors'], \n",
    "                        row['jaccard_coefficient'], \n",
    "                        row['genre_overlap'], \n",
    "                        row['community_overlap'],\n",
    "                        CN_W,\n",
    "                        JACCARD_W,\n",
    "                        GENRE_W,\n",
    "                        COMMUNITY_W\n",
    "                    ), axis=1)\n",
    "                \n",
    "                # Classify based on threshold 0.5\n",
    "                link_pred_df['predicted_label'] = (link_pred_df['predicted_score'] >= 0.5).astype(int)\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                accuracy = (link_pred_df['predicted_label'] == link_pred_df['edge_exists']).mean()\n",
    "                \n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_params = (CN_W, JACCARD_W, GENRE_W, COMMUNITY_W)\n",
    "                    \n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "print(f\"Best Parameters: CN_WEIGHT={best_params[0]}, JACCARD_WEIGHT={best_params[1]}, GENRE_WEIGHT={best_params[2]}, COMMUNITY_WEIGHT={best_params[3]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2239d37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.9854267184587799\n",
      "Precision-Recall AUC: 0.456117109078475\n",
      "Hits@100: 0.023727137913989126\n"
     ]
    }
   ],
   "source": [
    "# ========== AUC-ROC EVALUATION ==========\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(link_pred_df['edge_exists'], link_pred_df['predicted_score'])\n",
    "print(f\"AUC-ROC: {auc}\")\n",
    "\n",
    "# ========== Precision-Recall EVALUATION ==========\n",
    "from sklearn.metrics import precision_recall_curve, auc as auc_metric\n",
    "precision, recall, _ = precision_recall_curve(link_pred_df['edge_exists'], link_pred_df['predicted_score'])\n",
    "pr_auc = auc_metric(recall, precision)\n",
    "print(f\"Precision-Recall AUC: {pr_auc}\")\n",
    "\n",
    "# ========== Hits@K EVALUATION ==========   \n",
    "def hits_at_k(df, k):\n",
    "    # Sort by predicted score descending\n",
    "    df_sorted = df.sort_values(by='predicted_score', ascending=False)\n",
    "    \n",
    "    # Get top K predictions\n",
    "    top_k = df_sorted.head(k)\n",
    "    \n",
    "    # Calculate Hits@K\n",
    "    hits = top_k['edge_exists'].sum()\n",
    "    total_positives = df['edge_exists'].sum()\n",
    "    \n",
    "    return hits / total_positives if total_positives > 0 else 0 \n",
    "hits_k = 100\n",
    "hits_at_100 = hits_at_k(link_pred_df, hits_k)\n",
    "print(f\"Hits@{hits_k}: {hits_at_100}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
